{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"L04qs.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xFrzPlyoikd9","colab_type":"text"},"source":["What do you think will happen to the accuracy of training a neural network as the number of layers increases? Try training a neural network for the MNIST data using more layers to see what happens. Speculate as to why you are seeing what you are seeing."]},{"cell_type":"code","metadata":{"id":"UZ27Nqb8TBKx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593115578691,"user_tz":240,"elapsed":27038,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["# Read in the mnist digit dataset\n","\n","from sklearn.datasets import fetch_openml\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import check_random_state\n","import random\n","from sklearn import tree\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.neural_network import MLPClassifier\n","\n","X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KB0MV4C1jCAC","colab_type":"text"},"source":["Next, we will divide the data into a training set and test set, randomly selecting 5000 examples for training"]},{"cell_type":"code","metadata":{"id":"IJ2-XGCVTBK3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593115580332,"user_tz":240,"elapsed":1638,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["train_samples = 5000\n","\n","random_state = check_random_state(0)\n","permutation = random_state.permutation(X.shape[0])\n","X = X[permutation]\n","y = y[permutation]\n","X = X.reshape((X.shape[0], -1))\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, train_size=train_samples, test_size=10000)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CTpGs2l-kdOs","colab_type":"text"},"source":["Now, we will try 10 hidden units in each of 1 to 10 layers, keeping track of the min/mean/max accuracy of models at each number of layers over ten runs.\n","\n"]},{"cell_type":"code","metadata":{"id":"FFoZESbCupY3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1593118567261,"user_tz":240,"elapsed":1256680,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"bcd8e80b-764d-4472-c55d-9435d87f7a2e"},"source":["reps = 10\n","for i in range(1,11):\n","  nhidden = i*[100]\n","  accsum,accmin,accmax = 0.0,1.0,0.0\n","  for r in range(reps):\n","    clf = MLPClassifier(hidden_layer_sizes=nhidden, max_iter = 10000)\n","    clf.fit(X_train, y_train)\n","    score = clf.score(X_test, y_test)\n","    accsum += score\n","    accmin = min(accmin, score)\n","    accmax = max(accmax, score)\n","  print(i, accmin, accsum/reps, accmax)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["1 0.8696 0.88229 0.8923\n","2 0.8584 0.8683400000000001 0.878\n","3 0.8442 0.85788 0.8673\n","4 0.8638 0.8722900000000001 0.8782\n","5 0.8817 0.88993 0.9004\n","6 0.8868 0.8956899999999999 0.9046\n","7 0.8987 0.9082800000000001 0.9179\n","8 0.9074 0.9196899999999999 0.9272\n","9 0.891 0.9213099999999999 0.936\n","10 0.9117 0.9243399999999999 0.9389\n"],"name":"stdout"}]}]}
